{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0367f0ef-044b-40c7-a4e5-b77bf24d83b1",
   "metadata": {},
   "source": [
    "# 1. From MapReduce to Beam\n",
    "\n",
    "* MapReduce is an architecture for the distributed processing of large quantities of data (originally for ranking online searches) proposed by Google in 2004 [1].\n",
    "* It is no longer encouraged by Google since 2014, but the design can be found in many more modern architectures for distributed computing [2].\n",
    "* It has 4 components **Mapper**, **Combiner**, **Partitioner**, **Reducer** [1].\n",
    "<img src=\"public/images/MapReduce_Architecture.png\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4171f8-15b3-45d4-8d6a-75020fc0c4ed",
   "metadata": {},
   "source": [
    "There are 3 functions that are the basic components of **Apache Beam**:\n",
    "\n",
    "1. [Map](https://beam.apache.org/documentation/transforms/python/elementwise/map/)\n",
    "2. [FlatMap](https://beam.apache.org/documentation/transforms/python/elementwise/flatmap/)\n",
    "3. [ParDo](https://beam.apache.org/documentation/transforms/python/elementwise/pardo/)\n",
    "\n",
    "People would often confuse them. And I hope, after this notebook, you can utilize them effectively.\n",
    "***P.S. You can click on the keywords***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec4edf-9183-4948-9f26-8bf41edc1f66",
   "metadata": {},
   "source": [
    "## 1.1 Map\n",
    "\n",
    "This is the same as python's **Map** function for parallel processing. And it gauranttees **1 input 1 output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a9ab5d2-8708-4358-95f2-d75dfaf91ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from test_funcs import square\n",
    "\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "with Pool(2) as pool:\n",
    "    result = pool.map(square, numbers)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afdb9d76-54f8-4fb7-b913-83c335922aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  (p | beam.Create([1, 2, 3, 4, 5])\n",
    "     | \"Square\" >> beam.Map(square)\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756ad2e-299c-426a-a59a-e469d1c4cead",
   "metadata": {},
   "source": [
    "## 1.2 FlatMap\n",
    "\n",
    "This is the same as Map, but you flatten the result. It allows **0 to infinite output per input**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89dcfad8-241b-4346-aa21-09505c11e6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'World', 'One', 'potato,', 'two', 'potatoes,', 'three', 'potatoes,', 'four.', 'Five', 'potatoes']\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from test_funcs import split_string\n",
    "\n",
    "strings = [\"Hello World\", \"One potato, two potatoes, three potatoes, four. Five potatoes\", \"\"]\n",
    "with Pool(2) as pool:\n",
    "    result = pool.map(split_string, strings)\n",
    "    # Flatten The List\n",
    "    result = [\n",
    "        x\n",
    "        for xs in result\n",
    "        for x in xs\n",
    "    ]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ad81be5-2f77-464c-842c-596203e6db7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "One\n",
      "potato,\n",
      "two\n",
      "potatoes,\n",
      "three\n",
      "potatoes,\n",
      "four.\n",
      "Five\n",
      "potatoes\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from test_funcs import split_string\n",
    "\n",
    "def split_string(x):\n",
    "    return x.split()\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  (p | beam.Create([\"Hello World\", \"One potato, two potatoes, three potatoes, four. Five potatoes\", \"\"])\n",
    "     | \"split_string\" >> beam.FlatMap(split_string)\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b49ba0d-8f27-44a7-b05e-d4bfbf1eee65",
   "metadata": {},
   "source": [
    "### Comparison: Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bfd7bc4-5629-40fc-b133-1236fbbec2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'World']\n",
      "['One', 'potato,', 'two', 'potatoes,', 'three', 'potatoes,', 'four.', 'Five', 'potatoes']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def split_string(x):\n",
    "    return x.split()\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  (p | beam.Create([\"Hello World\", \"One potato, two potatoes, three potatoes, four. Five potatoes\", \"\"])\n",
    "     | \"split_string\" >> beam.Map(split_string)\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59f459-d1c0-478a-8524-c1a81200d03d",
   "metadata": {},
   "source": [
    "## 1.3 ParDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37587c4f-5767-409f-9e83-e0b19fc84d8f",
   "metadata": {},
   "source": [
    "***Mean*** Calculation is a good example to demonstrate the shortcoming of *FlatMap*\n",
    "\n",
    "Since Mean(Mean(1, 2), Mean(2, 3, 4)) $\\neq$ Mean(1, 2, 2, 3, 4), you need to be able to pass both the ***numerator*** and ***denominator***\n",
    "\n",
    "Suppose we have to count the average number of *occurrences per document of words*:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262927cf-44d9-4ae2-8603-bbe32694fd2c",
   "metadata": {},
   "source": [
    "### Version 1: Normal MapReduce Implementation\n",
    "```\n",
    "Method Map(String Document)\n",
    "    words = Document.split()\n",
    "    Emit(String word, Integer freq)  #('potato', 2), ('potato', 1)|('potato', 1)\n",
    "\n",
    "Method Combine(String word, Integers [freq1, freq2, ...])\n",
    "    for freq in [freq1, ...]:\n",
    "        sum <- sum + freq\n",
    "        cnt <- cnt + 1\n",
    "    Emit(String word, [Integer sum, Integer cnt])  #('potato', (3, 2))|('potato', (1, 1))\n",
    "\n",
    "# all the same *word* goes to the same Reduce function\n",
    "Method Partition(String word, [Integer sum, Integer cnt])\n",
    "    Emit(String word)\n",
    "\n",
    "Method Reduce(Key String word, [(sum1, cnt1), (sum2, cnt2), ...]) #('potato', (3, 2), 'potato', (1, 1))\n",
    "    for sum, cnt in [(sum1, cnt1)...]:\n",
    "        sum_total <- sum_total + sum\n",
    "        cnt_total <- cnt_total + cnt\n",
    "    Emit(String word, sum_total / cnt_total)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6556c4-8de1-4d11-aafd-9e9e8e68eb87",
   "metadata": {},
   "source": [
    "### Version 2: Put Combine in Map\n",
    "```\n",
    "Method Map(String Document)\n",
    "    words = Document.split()\n",
    "    for freq in [freq1, ...]:\n",
    "        sum <- sum + freq\n",
    "        cnt <- cnt + 1\n",
    "    Emit(String word, Integer [Integer sum, Integer cnt])\n",
    "\n",
    "# all the same *word* goes to the same Reduce function\n",
    "Method Partition(String word, [Integer sum, Integer cnt])\n",
    "    Emit(String word)\n",
    "\n",
    "Method Reduce(Key String word, [(sum1, cnt1), (sum2, cnt2), ...])\n",
    "    for sum, cnt in [(sum1, cnt1)...]:\n",
    "        sum_total <- sum_total + sum\n",
    "        cnt_total <- cnt_total + cnt\n",
    "    Emit(String word, sum_total / cnt_total)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3aed9e-91b1-40bd-941e-4d263736c138",
   "metadata": {},
   "source": [
    "### Version 3: Map & Reduce -> Do, and build Partition into Them\n",
    "```\n",
    "Method ParDo(Key None, String Document)\n",
    "    words = Document.split()\n",
    "    for freq in [freq1, ...]:\n",
    "        sum <- sum + freq\n",
    "        cnt <- cnt + 1\n",
    "    Emit(String word, Integer [Integer sum, Integer cnt])\n",
    "\n",
    "Method ParDo(Key String word, [(sum1, cnt1), (sum2, cnt2), ...])\n",
    "    for sum, cnt in [(sum1, cnt1)...]:\n",
    "        sum_total <- sum_total + sum\n",
    "        cnt_total <- cnt_total + cnt\n",
    "    Emit(String word, sum_total / cnt_total)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea77bf42-7fdf-4cfc-a2cc-6c260c2f1329",
   "metadata": {},
   "source": [
    "### MapReduce Style in Apache Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b13f759-5720-49e3-a0ae-4138822f0b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.transforms.userstate import *\n",
    "\n",
    "class defineKey(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        key = element[\"key\"]\n",
    "        yield (key, element)\n",
    "\n",
    "def get_occurrence_dict(lst):\n",
    "    occurrence_dict = {}\n",
    "    \n",
    "    for item in lst:\n",
    "        if item in occurrence_dict:\n",
    "            occurrence_dict[item] += 1\n",
    "        else:\n",
    "            occurrence_dict[item] = 1\n",
    "    \n",
    "    return occurrence_dict\n",
    "\n",
    "class Mapper(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        key, data = element\n",
    "        for row in data:\n",
    "            value = row['value']\n",
    "            occurrence_dict = get_occurrence_dict(value)\n",
    "\n",
    "            for word, occur in occurrence_dict.items():\n",
    "                yield (key, {\"word\": word, \"occur\": occur})\n",
    "\n",
    "class Combiner(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        \n",
    "        frequency_dict = dict()\n",
    "        document_dict = dict()\n",
    "        \n",
    "        key, data = element\n",
    "        for row in data:\n",
    "            frequency_dict[row['word']] = frequency_dict.get(row['word'], 0) + row['occur']\n",
    "            document_dict[row['word']] = document_dict.get(row['word'], 0) + 1\n",
    "\n",
    "        for key, value in frequency_dict.items():\n",
    "            yield (key, {'freq': value, 'doc': document_dict[key]})\n",
    "\n",
    "class Reducer(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        key, data = element\n",
    "        freq = 0\n",
    "        doc = 0\n",
    "        for d in data:\n",
    "            freq += d['freq']\n",
    "            doc += d['doc']\n",
    "        yield (key, freq/doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d58d43-95d6-4d22-b1ff-9afa4c6767d7",
   "metadata": {},
   "source": [
    "### Mapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b43edbd-4cc8-4508-a961-311c8769b200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, {'word': 'potato', 'occur': 1})\n",
      "(0, {'word': 'potato', 'occur': 1})\n",
      "(0, {'word': 'tomato', 'occur': 1})\n",
      "(1, {'word': 'potato', 'occur': 1})\n",
      "(1, {'word': 'tomato', 'occur': 1})\n",
      "(1, {'word': 'potato', 'occur': 1})\n",
      "(1, {'word': 'tomato', 'occur': 2})\n",
      "(1, {'word': 'potato', 'occur': 3})\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "  (p | beam.Create([\n",
    "          {\"value\": ['potato'], \"key\": 0},\n",
    "          {\"value\": ['potato', 'tomato'], \"key\": 0}, \n",
    "          {\"value\": ['potato', 'tomato'], \"key\": 1},\n",
    "          {\"value\": ['potato', 'tomato', 'tomato'], \"key\": 1},\n",
    "          {\"value\": ['potato', 'potato', 'potato'], \"key\": 1}\n",
    "      ])\n",
    "     | \"Define_Key\" >> beam.ParDo(defineKey())\n",
    "     | \"Partitioner1\" >> beam.GroupByKey()\n",
    "     | \"Mean_Mapper\" >> beam.ParDo(Mapper())\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d400f2-9f44-429e-a0a0-b3e79a209191",
   "metadata": {},
   "source": [
    "### Combiner\n",
    "Combine function exist to perform a local reduce operation first, if you are counting the word `the`, summing the `occur` and `doc` for **every article** on the internet is still a big task.\\\n",
    "`Combiner` exists to do a smaller scale total first to make the `Reducer`'s job easier [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14452393-d7bf-48bc-a097-47528241830b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('potato', {'freq': 2, 'doc': 2})\n",
      "('tomato', {'freq': 1, 'doc': 1})\n",
      "('potato', {'freq': 5, 'doc': 3})\n",
      "('tomato', {'freq': 3, 'doc': 2})\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "  (p | beam.Create([\n",
    "          {\"value\": ['potato'], \"key\": 0},\n",
    "          {\"value\": ['potato', 'tomato'], \"key\": 0}, \n",
    "          {\"value\": ['potato', 'tomato'], \"key\": 1},\n",
    "          {\"value\": ['potato', 'tomato', 'tomato'], \"key\": 1},\n",
    "          {\"value\": ['potato', 'potato', 'potato'], \"key\": 1}\n",
    "      ])\n",
    "     | \"Define_Key\" >> beam.ParDo(defineKey())\n",
    "     | \"Partitioner1\" >> beam.GroupByKey()\n",
    "     | \"Mean_Mapper\" >> beam.ParDo(Mapper())\n",
    "     | \"Partitioner2\" >> beam.GroupByKey()\n",
    "     | \"Mean_Combiner\" >> beam.ParDo(Combiner())\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fa9b04-92f0-4d44-b044-e4acc2b79d5c",
   "metadata": {},
   "source": [
    "### Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0881efc4-b6ce-42bf-82bd-aa00d5dc39eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('potato', 1.4)\n",
      "('tomato', 1.3333333333333333)\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:\n",
    "  (p | beam.Create([\n",
    "          {\"value\": ['potato'], \"key\": 0},\n",
    "          {\"value\": ['potato', 'tomato'], \"key\": 0}, \n",
    "          {\"value\": ['potato', 'tomato'], \"key\": 1},\n",
    "          {\"value\": ['potato', 'tomato', 'tomato'], \"key\": 1},\n",
    "          {\"value\": ['potato', 'potato', 'potato'], \"key\": 1}\n",
    "      ])\n",
    "     | \"Define_Key\" >> beam.ParDo(defineKey())\n",
    "     | \"Partitioner1\" >> beam.GroupByKey()\n",
    "     | \"Mean_Mapper\" >> beam.ParDo(Mapper())\n",
    "     | \"Partitioner2\" >> beam.GroupByKey()\n",
    "     | \"Mean_Combiner\" >> beam.ParDo(Combiner())\n",
    "     | \"Partitioner3\" >> beam.GroupByKey()\n",
    "     | \"Mean_Reducer\" >> beam.ParDo(Reducer())\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94e5089-d8c2-4c42-8abc-e1f487c8234b",
   "metadata": {},
   "source": [
    "### Or just use default functions\n",
    "\n",
    "Mean is a common aggregate function that is already implemented, and the source code is doing the exact same thing:\n",
    "https://beam.apache.org/documentation/transforms/python/aggregation/mean/\n",
    "<img src=\"public/images/Mean_of_Apache_Beam.png\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f471b-5293-4aec-b667-27c83bf8482b",
   "metadata": {},
   "source": [
    "## 1.4 Conclusion:\n",
    "\n",
    "1. Map == multiprocessing.pool.map()\n",
    "2. FlatMap == flatten(multiprocessing.pool.map())\n",
    "3. ParDo == **whole MapReduce**:\n",
    "    * Allows Memory state (vs FlatMap)\n",
    "    * Allows Partition by Key (vs FlatMap)\n",
    "    * Hence, enable much more complex Algorithms, i.e. `Page Rank`, `Bellman–Ford`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6e2eec-1b39-404b-84a5-a54c0ecb1e51",
   "metadata": {},
   "source": [
    "# 2. Our Streaming Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e2d42-3896-496f-a5fc-e19c693f844d",
   "metadata": {},
   "source": [
    "## 2.1 App Usage\n",
    "\n",
    "***TODO:*** Convert `time` and `last_time_used` to timestamp using `pd.to_datetime(?, \"ms\")` and rename `total_fg_time` to `foreground_time_(ms)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17b7a143-68dc-4ab3-8c50-4cf8b7a74d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class '__main__.tranformations'>)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "class tranformations(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        import pandas as pd \n",
    "        ### YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  (p | beam.Create([\n",
    "      {\n",
    "        'time': 1524550039846,\n",
    "        'package_name': 'com.google.android.youtube',\n",
    "        'last_time_used': 1524438939878,\n",
    "        'total_fg_time': 857910,\n",
    "        'user_id': 'user_0'},\n",
    "     {\n",
    "        'time': 1524550039846,\n",
    "        'package_name': 'com.samsung.android.app.galaxyfinder',\n",
    "        'last_time_used': 1524438952278,\n",
    "        'total_fg_time': 64158,\n",
    "        'user_id': 'user_0'},\n",
    "     {\n",
    "        'time': 1524550039846,\n",
    "        'package_name': 'com.samsung.android.incallui',\n",
    "        'last_time_used': 1524480748673,\n",
    "        'total_fg_time': 321040,\n",
    "        'user_id': 'user_0'}])\n",
    "     | \"Transformations\" >> beam.ParDo(tranformations())\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a88f6-3691-492e-9efe-d68a609304b8",
   "metadata": {},
   "source": [
    "### Output:\n",
    "{'time': Timestamp('2018-04-24 06:07:19.846000'), 'package_name': 'com.google.android.youtube', 'last_time_used': Timestamp('2018-04-22 23:15:39.878000'), 'foreground_time_(ms)': 857910, 'user_id': 'user_0'} \\\n",
    "{'time': Timestamp('2018-04-24 06:07:19.846000'), 'package_name': 'com.samsung.android.app.galaxyfinder', 'last_time_used': Timestamp('2018-04-22 23:15:52.278000'), 'foreground_time_(ms)': 64158, 'user_id': 'user_0'} \\\n",
    "{'time': Timestamp('2018-04-24 06:07:19.846000'), 'package_name': 'com.samsung.android.incallui', 'last_time_used': Timestamp('2018-04-23 10:52:28.673000'), 'foreground_time_(ms)': 321040, 'user_id': 'user_0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830dc48-ed1b-445e-bee7-5d03ca9a0562",
   "metadata": {},
   "source": [
    "## 2.2 Locations\n",
    "\n",
    "***TODO:*** Drop \"acc\", \"alt\", \"bearing\", \"postime\", and convert `time` to timestamp using `datetime.utcfromtimestamp`\n",
    "(**NOTE: `utcfromtimestamp` uses *second*, but our data is in *milliseconds*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "417525b1-fa12-4c67-b268-5d3734d74110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from datetime import datetime\n",
    "\n",
    "def transform(element):\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "\n",
    "  (p | beam.Create([{\n",
    "        'time': 1524551239484,\n",
    "        'lat': 43.7068094,\n",
    "        'long': 10.4036635,\n",
    "        'speed': 0.0,\n",
    "        'acc': 400.0,\n",
    "        'alt': 0.0,\n",
    "        'bearing': 0.0,\n",
    "        'postime': 1524551040134,\n",
    "        'label': 'free_time',\n",
    "        'place_type': 'route',\n",
    "        'user_id': 'user_0'},\n",
    "    {\n",
    "        'time': 1524551539483,\n",
    "        'lat': 43.7068094,\n",
    "        'long': 10.4036635,\n",
    "        'speed': 0.0,\n",
    "        'acc': 400.0,\n",
    "        'alt': 0.0,\n",
    "        'bearing': 0.0,\n",
    "        'postime': 1524551040134,\n",
    "        'label': 'free_time',\n",
    "        'place_type': 'route',\n",
    "        'user_id': 'user_0'},\n",
    "    {\n",
    "        'time': 1524551839681,\n",
    "        'lat': 43.716982,\n",
    "        'long': 10.4026103,\n",
    "        'speed': 0.0,\n",
    "        'acc': 899.9989999999997,\n",
    "        'alt': 0.0,\n",
    "        'bearing': 0.0,\n",
    "        'postime': 1524551654162,\n",
    "        'label': 'free_time',\n",
    "        'place_type': 'health',\n",
    "        'user_id': 'user_0'}])\n",
    "     | \"Transformations\" >> beam.Map(transform)\n",
    "     | beam.LogElements())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88378356-3a27-48b6-8b4a-6b5dd22ddee1",
   "metadata": {},
   "source": [
    "### Output:\n",
    "{'time': datetime.datetime(2018, 4, 24, 6, 27, 19, 484000), 'lat': 43.7068094, 'long': 10.4036635, 'speed': 0.0, 'label': 'free_time', 'place_type': 'route', 'user_id': 'user_0'} \\\n",
    "{'time': datetime.datetime(2018, 4, 24, 6, 32, 19, 483000), 'lat': 43.7068094, 'long': 10.4036635, 'speed': 0.0, 'label': 'free_time', 'place_type': 'route', 'user_id': 'user_0'} \\\n",
    "{'time': datetime.datetime(2018, 4, 24, 6, 37, 19, 681000), 'lat': 43.716982, 'long': 10.4026103, 'speed': 0.0, 'label': 'free_time', 'place_type': 'health', 'user_id': 'user_0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb0d83a-3ab0-4a03-9a9c-fe9ac755eced",
   "metadata": {},
   "source": [
    "## 2.3 Calls\n",
    "\n",
    "***TODO:*** Group the calls by `incoming`, `phone_number`, `registered` & `user_id` and count the number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bae784ce-5e0a-47e3-9eb4-d90f6a765700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'incoming': True, 'phone_number': 'user_13', 'registered': True, 'user_id': 'user_0', 'count': 1}\n",
      "{'incoming': True, 'phone_number': 'phone_958', 'registered': True, 'user_id': 'user_0', 'count': 2}\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import json\n",
    "\n",
    "def define_key(element):\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def expand(element):\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "  (p | beam.Create([{\n",
    "      'time': 1524549275699,\n",
    "      'incoming': True,\n",
    "      'phone_number': 'user_13',\n",
    "      'registered': True,\n",
    "      'user_id': 'user_0'},\n",
    "     {\n",
    "      'time': 1524549070890,\n",
    "      'incoming': True,\n",
    "      'phone_number': 'phone_958',\n",
    "      'registered': True,\n",
    "      'user_id': 'user_0'},\n",
    "     {\n",
    "      'time': 1524549030099,\n",
    "      'incoming': True,\n",
    "      'phone_number': 'phone_958',\n",
    "      'registered': True,\n",
    "      'user_id': 'user_0'},])\n",
    "     | \"Define_Key\" >> ### YOUR CODE HERE\n",
    "     | 'Count elements per key' >> beam.combiners.Count.PerKey()\n",
    "     | 'Turn the key back to dictionary' >> ### YOUR CODE HERE\n",
    "     | beam.LogElements())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a2c136-ad29-4970-9f35-6740d80855fe",
   "metadata": {},
   "source": [
    "### Output:\n",
    "{'incoming': True, 'phone_number': 'user_13', 'registered': True, 'user_id': 'user_0', 'count': 1} \\\n",
    "{'incoming': True, 'phone_number': 'phone_958', 'registered': True, 'user_id': 'user_0', 'count': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f5ecc-e3e7-4adb-990c-98c4940663c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
